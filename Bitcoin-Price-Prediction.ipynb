{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>time_stamp</th>\n",
       "      <th>cost-per-transaction</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>estimated-transaction-volume</th>\n",
       "      <th>hash-rate</th>\n",
       "      <th>market-cap</th>\n",
       "      <th>market-price</th>\n",
       "      <th>median-confirmation-time</th>\n",
       "      <th>miners-revenue</th>\n",
       "      <th>n-orphaned-blocks</th>\n",
       "      <th>n-transactions</th>\n",
       "      <th>n-transactions-per-block</th>\n",
       "      <th>n-unique-addresses</th>\n",
       "      <th>total-bitcoins</th>\n",
       "      <th>transaction-fees</th>\n",
       "      <th>avg-block-size</th>\n",
       "      <th>transaction_to_trade_ratio_D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>01/03/2009 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.971027e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>01/05/2009 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>01/07/2009 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>01/09/2009 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.959438e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>01/11/2009 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.269289e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0           time_stamp  cost-per-transaction  difficulty  \\\n",
       "0           0  01/03/2009 00:00:00                   0.0         1.0   \n",
       "1           1  01/05/2009 00:00:00                   0.0         0.0   \n",
       "2           2  01/07/2009 00:00:00                   0.0         0.0   \n",
       "3           3  01/09/2009 00:00:00                   0.0         1.0   \n",
       "4           4  01/11/2009 00:00:00                   0.0         1.0   \n",
       "\n",
       "   estimated-transaction-volume     hash-rate  market-cap  market-price  \\\n",
       "0                           0.0  4.971027e-08         0.0           0.0   \n",
       "1                           0.0  0.000000e+00         0.0           0.0   \n",
       "2                           0.0  0.000000e+00         0.0           0.0   \n",
       "3                           0.0  6.959438e-07         0.0           0.0   \n",
       "4                           0.0  5.269289e-06         0.0           0.0   \n",
       "\n",
       "   median-confirmation-time  miners-revenue  n-orphaned-blocks  \\\n",
       "0                       0.0             0.0                0.0   \n",
       "1                       0.0             0.0                0.0   \n",
       "2                       0.0             0.0                0.0   \n",
       "3                       0.0             0.0                0.0   \n",
       "4                       0.0             0.0                0.0   \n",
       "\n",
       "   n-transactions  n-transactions-per-block  n-unique-addresses  \\\n",
       "0             1.0                       1.0                 1.0   \n",
       "1             0.0                       1.0                 0.0   \n",
       "2             0.0                       1.0                 0.0   \n",
       "3            14.0                       1.0                14.0   \n",
       "4           106.0                       1.0               106.0   \n",
       "\n",
       "   total-bitcoins  transaction-fees  avg-block-size  \\\n",
       "0            50.0               0.0        0.000285   \n",
       "1            50.0               0.0        0.000000   \n",
       "2            50.0               0.0        0.000000   \n",
       "3           750.0               0.0        0.000215   \n",
       "4          7600.0               0.0        0.000215   \n",
       "\n",
       "   transaction_to_trade_ratio_D  \n",
       "0                           0.0  \n",
       "1                           0.0  \n",
       "2                           0.0  \n",
       "3                           0.0  \n",
       "4                           0.0  "
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from io import StringIO\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# @hidden_cell\n",
    "# This function accesses a file in your Object Storage. The definition contains your credentials.\n",
    "# You might want to remove those credentials before you share your notebook.\n",
    "def get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff(container, filename):\n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage.\"\"\"\n",
    "\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': 'member_6e6fb2aeb2891f1e6518800b3facd7562d18ac79','domain': {'id': '9d54dfb7f46d48d8930e2e61e1e7ddab'},\n",
    "            'password': 'Fl^J{l2v*M0cXWqv'}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', container, '/', filename])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.get(url=url2, headers=headers2)\n",
    "    return StringIO(resp2.text)\n",
    "\n",
    "df_data_1 = pd.read_csv(get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff('BITCOINTRANSACTIONNETWORKANALYSIS', 'Df_for_Prediction.csv'))\n",
    "df_data_1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def put_file(credentials, local_file_name):  \n",
    "    \"\"\"This functions returns a StringIO object containing\n",
    "    the file content from Bluemix Object Storage V3.\"\"\"\n",
    "    f = open(local_file_name,'r')\n",
    "    my_data = f.read()\n",
    "    url1 = ''.join(['https://identity.open.softlayer.com', '/v3/auth/tokens'])\n",
    "    data = {'auth': {'identity': {'methods': ['password'],\n",
    "            'password': {'user': {'name': credentials['username'],'domain': {'id': credentials['domain_id']},\n",
    "            'password': credentials['password']}}}}}\n",
    "    headers1 = {'Content-Type': 'application/json'}\n",
    "    resp1 = requests.post(url=url1, data=json.dumps(data), headers=headers1)\n",
    "    resp1_body = resp1.json()\n",
    "    for e1 in resp1_body['token']['catalog']:\n",
    "        if(e1['type']=='object-store'):\n",
    "            for e2 in e1['endpoints']:\n",
    "                        if(e2['interface']=='public'and e2['region']=='dallas'):\n",
    "                            url2 = ''.join([e2['url'],'/', credentials['container'], '/', local_file_name])\n",
    "    s_subject_token = resp1.headers['x-subject-token']\n",
    "    headers2 = {'X-Auth-Token': s_subject_token, 'accept': 'application/json'}\n",
    "    resp2 = requests.put(url=url2, headers=headers2, data = my_data )\n",
    "    print (resp2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1518, 18)"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df_data_1\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#using label encoder to convert categorical columns into numeric values\n",
    "def dummyEncode(df):\n",
    "        columnsToEncode = list(df)\n",
    "        le = LabelEncoder()\n",
    "        for feature in columnsToEncode:\n",
    "            try:\n",
    "                df[feature] = le.fit_transform(df[feature])\n",
    "            except:\n",
    "                print('Error encoding '+feature)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      2009-01-03\n",
       "1      2009-01-05\n",
       "2      2009-01-07\n",
       "3      2009-01-09\n",
       "4      2009-01-11\n",
       "5      2009-01-13\n",
       "6      2009-01-15\n",
       "7      2009-01-17\n",
       "8      2009-01-19\n",
       "9      2009-01-21\n",
       "10     2009-01-23\n",
       "11     2009-01-25\n",
       "12     2009-01-27\n",
       "13     2009-01-29\n",
       "14     2009-01-31\n",
       "15     2009-02-02\n",
       "16     2009-02-04\n",
       "17     2009-02-06\n",
       "18     2009-02-08\n",
       "19     2009-02-10\n",
       "20     2009-02-12\n",
       "21     2009-02-14\n",
       "22     2009-02-16\n",
       "23     2009-02-18\n",
       "24     2009-02-20\n",
       "25     2009-02-22\n",
       "26     2009-02-24\n",
       "27     2009-02-26\n",
       "28     2009-02-28\n",
       "29     2009-03-02\n",
       "          ...    \n",
       "1488   2017-02-26\n",
       "1489   2017-02-28\n",
       "1490   2017-03-02\n",
       "1491   2017-03-04\n",
       "1492   2017-03-06\n",
       "1493   2017-03-08\n",
       "1494   2017-03-10\n",
       "1495   2017-03-12\n",
       "1496   2017-03-14\n",
       "1497   2017-03-16\n",
       "1498   2017-03-18\n",
       "1499   2017-03-20\n",
       "1500   2017-03-22\n",
       "1501   2017-03-24\n",
       "1502   2017-03-26\n",
       "1503   2017-03-28\n",
       "1504   2017-03-30\n",
       "1505   2017-04-01\n",
       "1506   2017-04-03\n",
       "1507   2017-04-05\n",
       "1508   2017-04-07\n",
       "1509   2017-04-09\n",
       "1510   2017-04-11\n",
       "1511   2017-04-13\n",
       "1512   2017-04-15\n",
       "1513   2017-04-17\n",
       "1514   2017-04-19\n",
       "1515   2017-04-21\n",
       "1516   2017-04-23\n",
       "1517   2017-04-25\n",
       "Name: time_stamp, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns\n",
    "df['time_stamp'] =  pd.to_datetime(df['time_stamp'])\n",
    "df['time_stamp'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  time_stamp  cost-per-transaction  difficulty  \\\n",
      "0           0           0                     0           1   \n",
      "1           1           1                     0           0   \n",
      "2           2           2                     0           0   \n",
      "3           3           3                     0           1   \n",
      "4           4           4                     0           1   \n",
      "\n",
      "   estimated-transaction-volume  hash-rate  market-cap  \\\n",
      "0                             0          1           0   \n",
      "1                             0          0           0   \n",
      "2                             0          0           0   \n",
      "3                             0          6           0   \n",
      "4                             0         62           0   \n",
      "\n",
      "   median-confirmation-time  miners-revenue  n-orphaned-blocks  \\\n",
      "0                         0               0                  0   \n",
      "1                         0               0                  0   \n",
      "2                         0               0                  0   \n",
      "3                         0               0                  0   \n",
      "4                         0               0                  0   \n",
      "\n",
      "   n-transactions  n-transactions-per-block  n-unique-addresses  \\\n",
      "0               1                         0                   1   \n",
      "1               0                         0                   0   \n",
      "2               0                         0                   0   \n",
      "3               6                         0                   6   \n",
      "4              65                         0                  63   \n",
      "\n",
      "   total-bitcoins  transaction-fees  avg-block-size  \\\n",
      "0               0                 0             208   \n",
      "1               0                 0               0   \n",
      "2               0                 0               0   \n",
      "3               1                 0               1   \n",
      "4               2                 0               7   \n",
      "\n",
      "   transaction_to_trade_ratio_D  \n",
      "0                             0  \n",
      "1                             0  \n",
      "2                             0  \n",
      "3                             0  \n",
      "4                             0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pearson_df=df.copy()\n",
    "#print(pearson_df.head())\n",
    "pearson_df=dummyEncode(df)\n",
    "#pearson_df=pearson_df[['acc_open_past_24mths','num_tl_op_past_12m','percent_bc_gt_75','term','revol_util','total_rec_int','meanfico','int_rate']]\n",
    "\n",
    "Y=pearson_df['market-price']\n",
    "pearson_df.drop('market-price', axis=1, inplace=True)\n",
    "X=pearson_df\n",
    "print(X.head())\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Unnamed: 0', 'time_stamp', 'cost-per-transaction', 'difficulty',\n",
      "       'estimated-transaction-volume', 'hash-rate', 'market-cap',\n",
      "       'median-confirmation-time', 'miners-revenue', 'n-orphaned-blocks',\n",
      "       'n-transactions', 'n-transactions-per-block', 'n-unique-addresses',\n",
      "       'total-bitcoins', 'transaction-fees', 'avg-block-size',\n",
      "       'transaction_to_trade_ratio_D'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#random split method for creating the training and test splits\n",
    "X_train_pearson, X_test_pearson, Y_train_pearson, Y_test_pearson = train_test_split(X,Y, test_size=0.2)\n",
    "print(X_train_pearson.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Features sorted by score: ['market-cap', 'miners-revenue', 'difficulty', 'n-unique-addresses', 'hash-rate', 'total-bitcoins', 'time_stamp', 'Unnamed: 0', 'n-transactions', 'avg-block-size', 'n-transactions-per-block', 'transaction-fees', 'cost-per-transaction', 'estimated-transaction-volume', 'median-confirmation-time', 'n-orphaned-blocks', 'transaction_to_trade_ratio_D']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "X_train_percentile, X_test_percentile, Y_train_percentile, Y_test_percentile = train_test_split(X, Y, test_size=0.2)\n",
    "feature_names = X.columns\n",
    "\n",
    "fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=20)\n",
    "X_train_fs = fs.fit_transform(X_train_percentile, Y_train_percentile)\n",
    "\n",
    "print ('***Features sorted by score:', [feature_names[i] for i in np.argsort(fs.scores_)[::-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['miners-revenue', 'difficulty', 'n-unique-addresses', 'hash-rate',\n",
       "       'total-bitcoins', 'n-transactions', 'avg-block-size',\n",
       "       'n-transactions-per-block', 'transaction-fees', 'cost-per-transaction',\n",
       "       'median-confirmation-time', 'n-orphaned-blocks',\n",
       "       'transaction_to_trade_ratio_D'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X=percentile_df[['total-bitcoins', 'n-orphaned-blocks', 'market-cap', 'difficulty', 'miners-revenue', 'hash-rate', 'median-confirmation-time', 'avg-block-size', 'cost-per-transaction', 'n-transactions-per-block', 'n-unique-addresses', 'n-transactions', 'trade-volume', 'estimated-transaction-volume', 'transaction_to_trade_ratio_D', 'transaction-fees']]\n",
    "\n",
    "columns=['miners-revenue', 'difficulty', 'n-unique-addresses', 'hash-rate', 'total-bitcoins','n-transactions', 'avg-block-size', 'n-transactions-per-block', 'transaction-fees', 'cost-per-transaction', 'median-confirmation-time', 'n-orphaned-blocks', 'transaction_to_trade_ratio_D']\n",
    "\n",
    "X=X[columns]\n",
    "X.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing market cap it actuals gives BTC price in USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(1.0, 'transaction_to_trade_ratio_D'), (1.0, 'transaction-fees'), (1.0, 'total-bitcoins'), (1.0, 'n-unique-addresses'), (1.0, 'n-transactions-per-block'), (1.0, 'n-transactions'), (1.0, 'n-orphaned-blocks'), (1.0, 'miners-revenue'), (1.0, 'median-confirmation-time'), (1.0, 'hash-rate'), (1.0, 'difficulty'), (1.0, 'cost-per-transaction'), (1.0, 'avg-block-size')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "lasso_df=df.copy()\n",
    "\n",
    "# X=lasso_df.ix[:, lasso_df.columns != 'int_rate']\n",
    "# X=dummyEncode(X)\n",
    "# Y=lasso_df.int_rate\n",
    "\n",
    "rlasso = RandomizedLasso(alpha='bic', verbose=False, n_resampling=50, random_state=1001, n_jobs=1)\n",
    "rlasso.fit(X, Y)\n",
    " \n",
    "print( \"Features sorted by their score:\")\n",
    "coef = pd.DataFrame(rlasso.scores_, columns = ['RandomizedLasso_score'])\n",
    "\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), X), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'n-orphaned-blocks'), (2, 'difficulty'), (3, 'hash-rate'), (4, 'miners-revenue'), (5, 'total-bitcoins'), (6, 'median-confirmation-time'), (7, 'n-unique-addresses'), (8, 'avg-block-size'), (9, 'transaction_to_trade_ratio_D'), (10, 'transaction-fees'), (11, 'n-transactions-per-block'), (12, 'n-transactions'), (13, 'cost-per-transaction')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# rfe_df=df.copy()\n",
    "# rfe_df.ix[:, rfe_df.columns != 'int_rate']=dummyEncode(rfe_df.ix[:, rfe_df.columns != 'int_rate'])\n",
    "\n",
    "\n",
    "X_train_rfe, X_test_rfe, Y_train_rfe, Y_test_rfe = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "\n",
    "rfe.fit(X_train_rfe,Y_train_rfe)\n",
    " \n",
    "print (\"Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), X_train_rfe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Linear Regression algorithm\n",
      "Intercept is  59.6475303175\n",
      "Coefficient is  [  7.15230456e-01   6.95006907e+00  -2.28094267e-01  -7.35822840e-01\n",
      "  -7.74405994e-02  -5.41164377e-03   7.43493130e-02   4.33002813e-02\n",
      "   4.78385083e-02  -9.64763217e-03   6.40036852e-02  -1.18598291e+01\n",
      "  -5.87050827e-02]\n",
      "Training score is  0.983292129525\n",
      "Testing score is  0.983646046168\n"
     ]
    }
   ],
   "source": [
    "from scipy import stats\n",
    "X_train_percentile, X_test_percentile, Y_train_percentile, Y_test_percentile = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "print(\"Starting Linear Regression algorithm\")\n",
    "linear_reg = LinearRegression()\n",
    "fit=linear_reg.fit(X_train_percentile, Y_train_percentile)\n",
    "\n",
    "print (\"Intercept is \",linear_reg.intercept_)\n",
    "print(\"Coefficient is \",linear_reg.coef_)\n",
    "print(\"Training score is \",linear_reg.score(X_train_percentile, Y_train_percentile))\n",
    "print(\"Testing score is \",linear_reg.score(X_test_percentile, Y_test_percentile))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Linear Regression algorithm\n",
      "Intercept is  56.4501515829\n",
      "Coefficient is  [  7.02698355e-01   6.79607111e+00  -2.49823782e-01  -7.00377651e-01\n",
      "  -6.43591949e-02  -4.82222938e-03   8.56902632e-02   3.19867522e-02\n",
      "   4.79088821e-02   1.49229150e-04   5.72082646e-02  -1.42891397e+01\n",
      "  -6.41738581e-02]\n",
      "Training score is  0.983612234158\n",
      "Testing score is  0.982252938009\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_rfe, X_test_rfe, Y_train_rfe, Y_test_rfe = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "print(\"Starting Linear Regression algorithm\")\n",
    "linear_reg = LinearRegression()\n",
    "fit=linear_reg.fit(X_train_rfe, Y_train_rfe)\n",
    "\n",
    "print (\"Intercept is \",linear_reg.intercept_)\n",
    "print(\"Coefficient is \",linear_reg.coef_)\n",
    "\n",
    "print(\"Training score is \",linear_reg.score(X_train_rfe, Y_train_rfe))\n",
    "\n",
    "print(\"Testing score is \",linear_reg.score(X_test_rfe, Y_test_rfe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Neural Network\n",
      "Training score is  0.999848250296\n",
      "Testing score is  0.999410415031\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# common features from RFE and Select Percentile are\n",
    "# grade, loan_status, fico_range_grade, grade_based_on_inq_last_6mths, acc_open_past_24mths, total_acc, issue_d, meanfico\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "\n",
    "#neural network\n",
    "print(\"Staring Neural Network\")\n",
    "\n",
    "X_train_nn, X_test_nn, Y_train_nn, Y_test_nn = train_test_split(X,Y, test_size=0.7)\n",
    "\n",
    "\n",
    "X_train_nn = StandardScaler().fit_transform(X_train_nn)\n",
    "X_test_nn = StandardScaler().fit_transform(X_test_nn)\n",
    "\n",
    "mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,\n",
    "                           max_iter=150, shuffle=True, random_state=12)\n",
    "mlp.fit(X_train_nn, Y_train_nn)\n",
    "print(\"Training score is \",mlp.score(X_train_nn, Y_train_nn))\n",
    "print(\"Testing score is \",mlp.score(X_test_nn, Y_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting KNN algorithm\n",
      "Accuracy of the model is  0.995856905038\n",
      "Accuracy of the model is  0.997074821151\n",
      "Accuracy of the model is  0.997292067536\n",
      "Accuracy of the model is  0.997413062258\n",
      "Accuracy of the model is  0.997148406759\n",
      "Accuracy of the model is  0.997196691135\n",
      "Accuracy of the model is  0.997064730705\n",
      "Accuracy of the model is  0.997041830638\n",
      "Accuracy of the model is  0.996773863149\n",
      "Accuracy of the model is  0.996602694248\n",
      "Accuracy of the model is  0.996474230978\n",
      "Accuracy of the model is  0.996257225126\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# knn_df=df.copy()\n",
    "# knn_df=knn_df[['grade', 'total_pymnt_inv', 'revol_util', 'loan_status', 'fico_range_grade', 'total_rec_prncp', 'revol_bal', 'grade_based_on_inq_last_6mths', 'acc_open_past_24mths', 'installment', 'last_pymnt_amnt', 'funded_amnt_inv', 'total_acc', 'credit_age', 'issue_d', 'annual_inc', 'meanfico','int_rate']]\n",
    "\n",
    "# knn_df.ix[:, knn_df.columns != 'int_rate']=dummyEncode(knn_df.ix[:, knn_df.columns != 'int_rate'])\n",
    "\n",
    "X_train_knn, X_test_knn, Y_train_knn, Y_test_knn = train_test_split(X,Y, test_size=0.2)\n",
    "\n",
    "\n",
    "print(\"Starting KNN algorithm\")\n",
    "for K in range(12):\n",
    "         K_value = K+1\n",
    "         knn_reg = KNeighborsRegressor(n_neighbors = K_value, weights='uniform', algorithm='auto')\n",
    "         knn_reg.fit(X_train_knn, Y_train_knn)\n",
    "         y_pred = knn_reg.predict(X_test_knn)\n",
    "\n",
    "         print(\"Accuracy of the model is \",r2_score(Y_test_knn,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Random forest algorithm\n",
      "Accuracy of the model is  0.999963695812\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "\n",
    "X_train_random, X_test_random, Y_train_random, Y_test_random = train_test_split(X, Y, test_size=0.2)\n",
    "\n",
    "\n",
    "print(\"Staring Random forest algorithm\")\n",
    "random_forest = RandomForestRegressor(n_estimators= 8,n_jobs=2, max_depth=32, min_samples_leaf =1)\n",
    "random_forest.fit(X_train_random, Y_train_random)\n",
    "y_pred=random_forest.predict(X_test_random)\n",
    "print(\"Accuracy of the model is \",r2_score(Y_test_random,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_data_2 = pd.read_csv(get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff('BITCOINTRANSACTIONNETWORKANALYSIS', 'data.csv'))\n",
    "df_data_2.head()\n",
    "df_data_3 = pd.read_csv(get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff('BITCOINTRANSACTIONNETWORKANALYSIS', 'data-updated.csv'))\n",
    "df_data_3.head()\n",
    "df_data_4= pd.read_csv(get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff('BITCOINTRANSACTIONNETWORKANALYSIS', 'datanew.csv'))\n",
    "df_data_4.head()\n",
    "df_data_5= pd.read_csv(get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff('BITCOINTRANSACTIONNETWORKANALYSIS', 'data_more.csv'))\n",
    "df_data_5.head()\n",
    "df_data_6= pd.read_csv(get_object_storage_file_with_credentials_b6d2dc4304df42d5bf425b6ca8af67ff('BITCOINTRANSACTIONNETWORKANALYSIS', 'data_latest.csv'))\n",
    "df_data_6.head()\n",
    "frames = [df_data_2,df_data_3,df_data_4,df_data_5,df_data_6]\n",
    "\n",
    "df_bitfix=pd.concat(frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [201]>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# @hidden_cell\n",
    "credentials_2 = {\n",
    "  'auth_url':'https://identity.open.softlayer.com',\n",
    "  'project':'object_storage_b6d2dc43_04df_42d5_bf42_5b6ca8af67ff',\n",
    "  'project_id':'b27f8cf040e5488eb7ceb30211ba0896',\n",
    "  'region':'dallas',\n",
    "  'user_id':'ed411c6b7daa4284a2208c6d34cda037',\n",
    "  'domain_id':'9d54dfb7f46d48d8930e2e61e1e7ddab',\n",
    "  'domain_name':'1257643',\n",
    "  'username':'member_6e6fb2aeb2891f1e6518800b3facd7562d18ac79',\n",
    "  'password':\"\"\"Fl^J{l2v*M0cXWqv\"\"\",\n",
    "  'container':'BITCOINTRANSACTIONNETWORKANALYSIS',\n",
    "  'tenantId':'undefined',\n",
    "  'filename':'data_more.csv'\n",
    "}\n",
    "df_bitfix.to_csv(\"bitflix_merge_dataset.csv\")\n",
    "put_file(credentials_2,'bitflix_merge_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19543"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_bitfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['_id', 'width', 'mid', 'mid30', 'imbalance2', 'adj_price2',\n",
       "       'imbalance4', 'adj_price4', 'imbalance8', 'adj_price8', 't30_count',\n",
       "       't30_av', 'agg30', 'trend30', 't60_count', 't60_av', 'agg60', 'trend60',\n",
       "       't120_count', 't120_av', 'agg120', 'trend120', 't180_count', 't180_av',\n",
       "       'agg180', 'trend180'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bitfix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    _id  width  mid30  imbalance2  adj_price2  imbalance4  adj_price4  \\\n",
      "0  4018      7    667        1482        1890        1488        1847   \n",
      "1  4019      7    331        1482        1890        1488        1847   \n",
      "2  4020      7    331        1482        1890        1488        1847   \n",
      "3  4021      7    331        1505        1909        1495        1879   \n",
      "4  4022      7    331        1505        1909        1495        1879   \n",
      "\n",
      "   imbalance8  adj_price8  t30_count    ...     agg60  trend60  t120_count  \\\n",
      "0        1531        1752          5    ...       506       56          37   \n",
      "1        1531        1752          5    ...       506       56          37   \n",
      "2        1531        1752          4    ...       506       56          37   \n",
      "3        1523        1778          4    ...       506       56          36   \n",
      "4        1523        1778          4    ...       506       56          36   \n",
      "\n",
      "   t120_av  agg120  trend120  t180_count  t180_av  agg180  trend180  \n",
      "0     1179     182       530          42      882     273       325  \n",
      "1     1179     182       530          42      882     273       325  \n",
      "2     1179     182       530          42      882     273       325  \n",
      "3     1214     172       615          42      882     273       325  \n",
      "4     1214     172       615          42      882     273       325  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pearson_df=df_bitfix.copy()\n",
    "#print(pearson_df.head())\n",
    "pearson_df=dummyEncode(pearson_df)\n",
    "#pearson_df=pearson_df[['acc_open_past_24mths','num_tl_op_past_12m','percent_bc_gt_75','term','revol_util','total_rec_int','meanfico','int_rate']]\n",
    "\n",
    "Y_other=pearson_df['mid']\n",
    "pearson_df.drop('mid', axis=1, inplace=True)\n",
    "X_other=pearson_df\n",
    "print(X_other.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***Features sorted by score: ['_id', 'adj_price8', 'agg180', 'imbalance2', 'agg120', 'adj_price4', 'agg60', 'adj_price2', 'imbalance4', 'width', 'trend180', 'agg30', 'trend120', 'imbalance8', 'trend60', 't180_av', 'trend30', 't30_av', 'mid30', 't30_count', 't60_av', 't120_av', 't60_count', 't180_count', 't120_count']\n"
     ]
    }
   ],
   "source": [
    "from sklearn import feature_selection\n",
    "\n",
    "\n",
    "X_train_percentile, X_test_percentile, Y_train_percentile, Y_test_percentile = train_test_split(X_other, Y_other, test_size=0.2)\n",
    "feature_names = X_other.columns\n",
    "\n",
    "fs = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=20)\n",
    "X_train_fs = fs.fit_transform(X_train_percentile, Y_train_percentile)\n",
    "\n",
    "print ('***Features sorted by score:', [feature_names[i] for i in np.argsort(fs.scores_)[::-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their score:\n",
      "[(1.0, 'transaction_to_trade_ratio_D'), (1.0, 'transaction-fees'), (1.0, 'total-bitcoins'), (1.0, 'n-unique-addresses'), (1.0, 'n-transactions-per-block'), (1.0, 'n-transactions'), (1.0, 'n-orphaned-blocks'), (1.0, 'miners-revenue'), (1.0, 'median-confirmation-time'), (1.0, 'hash-rate'), (1.0, 'difficulty'), (1.0, 'cost-per-transaction'), (1.0, 'avg-block-size')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RandomizedLasso\n",
    "\n",
    "\n",
    "rlasso = RandomizedLasso(alpha='bic', verbose=False, n_resampling=50, random_state=1001, n_jobs=1)\n",
    "rlasso.fit(X_other, Y_other)\n",
    " \n",
    "print( \"Features sorted by their score:\")\n",
    "coef = pd.DataFrame(rlasso.scores_, columns = ['RandomizedLasso_score'])\n",
    "\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rlasso.scores_), X), reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features sorted by their rank:\n",
      "[(1, 'width'), (2, 't30_count'), (3, 't180_count'), (4, 't60_count'), (5, 't120_count'), (6, 'imbalance2'), (7, 'imbalance4'), (8, 'adj_price4'), (9, 'adj_price2'), (10, 'agg180'), (11, 'adj_price8'), (12, '_id'), (13, 'agg60'), (14, 'trend180'), (15, 'trend60'), (16, 'imbalance8'), (17, 'agg30'), (18, 'mid30'), (19, 'agg120'), (20, 't30_av'), (21, 't60_av'), (22, 'trend30'), (23, 'trend120'), (24, 't120_av'), (25, 't180_av')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# rfe_df=df.copy()\n",
    "# rfe_df.ix[:, rfe_df.columns != 'int_rate']=dummyEncode(rfe_df.ix[:, rfe_df.columns != 'int_rate'])\n",
    "\n",
    "X_train_rfe, X_test_rfe, Y_train_rfe, Y_test_rfe = train_test_split(X_other, Y_other, test_size=0.2)\n",
    "\n",
    "lr = LinearRegression()\n",
    "#rank all features, i.e continue the elimination until the last one\n",
    "rfe = RFE(lr, n_features_to_select=1)\n",
    "rfe.fit(X_train_rfe,Y_train_rfe)\n",
    " \n",
    "print (\"Features sorted by their rank:\")\n",
    "print (sorted(zip(map(lambda x: round(x, 4), rfe.ranking_), X_train_rfe)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'width', 'mid30', 'imbalance2', 'adj_price2', 'imbalance4',\n",
      "       'adj_price4', 'imbalance8', 'adj_price8', 't30_count', 't30_av',\n",
      "       'agg30', 'trend30', 't60_count', 't60_av', 'agg60', 'trend60',\n",
      "       't120_count', 't120_av', 'agg120', 'trend120', 't180_count', 't180_av',\n",
      "       'agg180', 'trend180'],\n",
      "      dtype='object')\n",
      "Starting Linear Regression algorithm\n",
      "Intercept is  83.4294622701\n",
      "Coefficient is  [  1.45491468e-02  -3.06117550e+00  -6.59626581e-03  -6.83443054e-02\n",
      "  -3.43948203e-02   4.35627986e-02   5.42088136e-02   8.93623399e-03\n",
      "  -3.99411257e-02  -1.48969680e-01  -3.30148739e-03   3.81148000e-03\n",
      "   1.85963311e-03  -1.76906376e-01   5.59609589e-03   1.43286646e-02\n",
      "  -1.10171492e-02   2.64785979e-01  -2.73367110e-03   5.89969698e-03\n",
      "   2.47524669e-03  -2.19478329e-01  -6.56546561e-04   2.37717757e-02\n",
      "  -1.19886462e-02]\n",
      "Training score is  0.729775947499\n",
      "Testing score is  0.730534846323\n"
     ]
    }
   ],
   "source": [
    "#random split method for creating the training and test splits\n",
    "X_train_pearson, X_test_pearson, Y_train_pearson, Y_test_pearson = train_test_split(X_other,Y_other, test_size=0.2)\n",
    "print(X_train_pearson.columns)\n",
    "print(\"Starting Linear Regression algorithm\")\n",
    "linear_reg = LinearRegression()\n",
    "fit=linear_reg.fit(X_train_pearson, Y_train_pearson)\n",
    "\n",
    "print (\"Intercept is \",linear_reg.intercept_)\n",
    "print(\"Coefficient is \",linear_reg.coef_)\n",
    "\n",
    "print(\"Training score is \",linear_reg.score(X_train_pearson, Y_train_pearson))\n",
    "\n",
    "print(\"Testing score is \",linear_reg.score(X_test_pearson, Y_test_pearson))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Neural Network\n",
      "Training score is  0.974993651759\n",
      "Testing score is  0.969886494866\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "#neural network\n",
    "print(\"Staring Neural Network\")\n",
    "\n",
    "X_train_nn, X_test_nn, Y_train_nn, Y_test_nn = train_test_split(X_other,Y_other, test_size=0.2)\n",
    "\n",
    "\n",
    "X_train_nn = StandardScaler().fit_transform(X_train_nn)\n",
    "X_test_nn = StandardScaler().fit_transform(X_test_nn)\n",
    "\n",
    "mlp = MLPRegressor(solver='lbfgs', hidden_layer_sizes=50,\n",
    "                           max_iter=150, shuffle=True, random_state=12)\n",
    "mlp.fit(X_train_nn, Y_train_nn)\n",
    "print(\"Training score is \",mlp.score(X_train_nn, Y_train_nn))\n",
    "print(\"Testing score is \",mlp.score(X_test_nn, Y_test_nn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['_id', 'width', 'mid30', 'imbalance2', 'adj_price2', 'imbalance4',\n",
      "       'adj_price4', 'imbalance8', 'adj_price8', 't30_count', 't30_av',\n",
      "       'agg30', 'trend30', 't60_count', 't60_av', 'agg60', 'trend60',\n",
      "       't120_count', 't120_av', 'agg120', 'trend120', 't180_count', 't180_av',\n",
      "       'agg180', 'trend180'],\n",
      "      dtype='object')\n",
      "Starting KNN algorithm\n",
      "Accuracy of the model is  0.999998206891\n",
      "Accuracy of the model is  0.99995869445\n",
      "Accuracy of the model is  0.999844554514\n",
      "Accuracy of the model is  0.999721083474\n",
      "Accuracy of the model is  0.999586964994\n",
      "Accuracy of the model is  0.99940333048\n",
      "Accuracy of the model is  0.999104599448\n",
      "Accuracy of the model is  0.99872650727\n",
      "Accuracy of the model is  0.998353193699\n",
      "Accuracy of the model is  0.997994685995\n",
      "Accuracy of the model is  0.997645702207\n",
      "Accuracy of the model is  0.997234339498\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# knn_df=df.copy()\n",
    "# knn_df=knn_df[['grade', 'total_pymnt_inv', 'revol_util', 'loan_status', 'fico_range_grade', 'total_rec_prncp', 'revol_bal', 'grade_based_on_inq_last_6mths', 'acc_open_past_24mths', 'installment', 'last_pymnt_amnt', 'funded_amnt_inv', 'total_acc', 'credit_age', 'issue_d', 'annual_inc', 'meanfico','int_rate']]\n",
    "\n",
    "# knn_df.ix[:, knn_df.columns != 'int_rate']=dummyEncode(knn_df.ix[:, knn_df.columns != 'int_rate'])\n",
    "print(X_other.columns)\n",
    "X_train_knn, X_test_knn, Y_train_knn, Y_test_knn = train_test_split(X_other,Y_other, test_size=0.2)\n",
    "\n",
    "\n",
    "print(\"Starting KNN algorithm\")\n",
    "for K in range(12):\n",
    "         K_value = K+1\n",
    "         knn_reg = KNeighborsRegressor(n_neighbors = K_value, weights='uniform', algorithm='auto')\n",
    "         knn_reg.fit(X_train_knn, Y_train_knn)\n",
    "         y_pred = knn_reg.predict(X_test_knn)\n",
    "\n",
    "         print(\"Accuracy of the model is \",r2_score(Y_test_knn,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Staring Random forest algorithm\n",
      "Accuracy of the model is  0.999733575191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# random_df=df.copy()\n",
    "# random_df=random_df[['grade', 'total_pymnt_inv', 'revol_util', 'loan_status', 'fico_range_grade', 'total_rec_prncp', 'revol_bal', 'grade_based_on_inq_last_6mths', 'acc_open_past_24mths', 'installment', 'last_pymnt_amnt', 'funded_amnt_inv', 'total_acc', 'credit_age', 'issue_d', 'annual_inc', 'meanfico','int_rate']]\n",
    "\n",
    "# random_df.ix[:, random_df.columns != 'int_rate']=dummyEncode(knn_df.ix[:, random_df.columns != 'int_rate'])\n",
    "\n",
    "X_train_random, X_test_random, Y_train_random, Y_test_random = train_test_split(X_other, Y_other, test_size=0.2)\n",
    "\n",
    "\n",
    "print(\"Staring Random forest algorithm\")\n",
    "random_forest = RandomForestRegressor(n_estimators= 8,n_jobs=2, max_depth=32, min_samples_leaf =1)\n",
    "random_forest.fit(X_train_random, Y_train_random)\n",
    "y_pred=random_forest.predict(X_test_random)\n",
    "print(\"Accuracy of the model is \",r2_score(Y_test_random,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import numpy as np\n",
    "import matplotlib.ticker as mtick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns=['_id', 'width', 'mid30', 'imbalance2', 'adj_price2', 'imbalance4',\n",
    "       'adj_price4', 'imbalance8', 'adj_price8', 't30_count', 't30_av',\n",
    "       'agg30', 'trend30', 't60_count', 't60_av', 'agg60', 'trend60',\n",
    "       't120_count', 't120_av', 'agg120', 'trend120', 't180_count', 't180_av',\n",
    "       'agg180', 'trend180']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def cross_validate(X, y, model, window):\n",
    "    '''\n",
    "    Cross validates time series data using a shifting window where train data is\n",
    "    always before test data\n",
    "    '''\n",
    "    in_sample_score = []\n",
    "    out_sample_score = []\n",
    "    x=(int)(len(y)/window)\n",
    "    \n",
    "    for i in range(1, x):\n",
    "        train_index = np.arange(0, i*window)\n",
    "        test_index = np.arange(i*window, (i+1)*window)\n",
    "        y_train = y.take(train_index)\n",
    "        y_test = y.take(test_index)\n",
    "        X_train = X.take(train_index, axis=0)\n",
    "        X_test = X.take(test_index, axis=0)\n",
    "        model.fit(X_train, y_train)\n",
    "        in_sample_score.append(model.score(X_train, y_train))\n",
    "        print('Model score on test',model.score(X_test, y_test))\n",
    "        out_sample_score.append(model.score(X_test, y_test))\n",
    "        #print('predcti',model.predict(X_test)[0])\n",
    "        print ('Window', i)\n",
    "        print ('in-sample score', in_sample_score[-1])\n",
    "        print ('out-sample score:', out_sample_score[-1])\n",
    "        print ('---')\n",
    "\n",
    "    return model, np.mean(in_sample_score), np.mean(out_sample_score)\n",
    "\n",
    "\n",
    "def fit_forest(X, y, window=100000, estimators=100,\n",
    "               samples_leaf=250, validate=True):\n",
    "    '''\n",
    "    Fits Random Forest\n",
    "    '''\n",
    "    model = RandomForestRegressor(n_estimators=estimators,\n",
    "                                  min_samples_leaf=samples_leaf,\n",
    "                                  random_state=42,\n",
    "                                  n_jobs=-1)\n",
    "    if validate:\n",
    "        return cross_validate(X, y, model, window)\n",
    "    return model.fit(X, y)\n",
    "\n",
    "\n",
    "def fit_boosting(X, y, window=100000, estimators=250, learning=.01,\n",
    "                 samples_leaf=500, depth=20, validate=False):\n",
    "    '''\n",
    "    Fits Gradient Boosting\n",
    "    '''\n",
    "    model = GradientBoostingRegressor(n_estimators=estimators,\n",
    "                                      learning_rate=learning,\n",
    "                                      min_samples_leaf=samples_leaf,\n",
    "                                      max_depth=depth,\n",
    "                                      random_state=42)\n",
    "    if validate:\n",
    "        return cross_validate(X, y, model, window)\n",
    "    return model.fit(X, y)\n",
    "\n",
    "\n",
    "def grid_search(X, y, split, learn=[.01], samples_leaf=[250, 350, 500],\n",
    "                depth=[10, 15]):\n",
    "    '''\n",
    "    Runs a grid search for GBM on split data\n",
    "    '''\n",
    "    for l in learn:\n",
    "        for s in samples_leaf:\n",
    "            for d in depth:\n",
    "                model = GradientBoostingRegressor(n_estimators=250,\n",
    "                                                  learning_rate=l,\n",
    "                                                  min_samples_leaf=s,\n",
    "                                                  max_depth=d,\n",
    "                                                  random_state=42)\n",
    "                model.fit(X.values[:split], y.values[:split])\n",
    "                in_score = model.score(X.values[:split], y.values[:split])\n",
    "                out_score = model.score(X.values[split:], y.values[split:])\n",
    "                print ('learning_rate: {}, min_samples_leaf: {}, max_depth: {}'.format(l, s, d))\n",
    "                print ('in-sample score:', in_score)\n",
    "                print ('out-sample score:', out_score)\n",
    "                print ('')\n",
    "\n",
    "\n",
    "def run_models(data, window, model_function, drop_zeros=False):\n",
    "    '''\n",
    "    Runs cross-validated models with a range of target offsets and outputs\n",
    "    results sorted by out-of-sample performance\n",
    "    '''\n",
    "    mids = [col for col in data.columns if 'mid' in col]\n",
    "    prevs = [col for col in data.columns if 'prev' in col]\n",
    "    print(\"prevs\",prevs)\n",
    "    in_reg_scores = {}\n",
    "    out_reg_scores = {}\n",
    "    for i in range(len(mids)):\n",
    "        print ('fitting model #{}...'.format(i+1))\n",
    "        m = mids[i]\n",
    "        #p = prevs[i]\n",
    "        if drop_zeros:\n",
    "            y = data[data[m] != 0][m].values\n",
    "            #prev = data[data[m] != 0][p]\n",
    "            #X = data[data[m] != 0].drop(mids+prevs, axis=1)\n",
    "            X = data[data[m] != 0].drop(mids, axis=1)\n",
    "            X = X.join(prev)\n",
    "            X = X.values\n",
    "        else:\n",
    "            y = data[m].values\n",
    "            #prev = data[p]\n",
    "            #X = data.drop(mids+prevs, axis=1)\n",
    "            X = data.drop(mids, axis=1)\n",
    "            #X = X.join(prev)\n",
    "            X = X.values\n",
    "\n",
    "         \n",
    "        _, in_reg_score, out_reg_score = model_function(X, y, window)\n",
    "        in_reg_scores[m] = in_reg_score\n",
    "        out_reg_scores[out_reg_score] = m\n",
    "\n",
    "    print ('\\nrandom forest regressor r^2:')\n",
    "    for score in sorted(out_reg_scores):\n",
    "        m = out_reg_scores[score]\n",
    "        print ('out-sample', m, score)\n",
    "        print ('in-sample', m, in_reg_scores[m], '\\n')\n",
    "\n",
    "\n",
    "def get_feature_importances(fitted_model, labels):\n",
    "    '''\n",
    "    Returns labels sorted by feature importance\n",
    "    '''\n",
    "    labels = np.array(labels)\n",
    "    importances = fitted_model.feature_importances_\n",
    "    indexes = np.argsort(importances)[::-1]\n",
    "    for i in indexes:\n",
    "        print ('{}: {}'.format(labels[i], importances[i]))\n",
    "    return labels[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_models(df_bitfix,10,fit_forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = GradientBoostingRegressor(n_estimators=250,\n",
    "                                  learning_rate=0.01,\n",
    "                                  min_samples_leaf=500,\n",
    "                                  max_depth=20,\n",
    "                                  random_state=42)\n",
    "X_train_gbr, X_test_gbr, Y_train_gbr, Y_test_gbr = train_test_split(X_other,Y_other, test_size=0.2)\n",
    "print(model.fit(X_train_gbr, Y_train_gbr))\n",
    "print(model.score(X_test_gbr,Y_test_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.5 (Experimental) with Spark 2.0",
   "language": "python",
   "name": "python3-spark20"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}